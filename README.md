# ğŸ“Š Analyse de ma recherche dâ€™emploi en Data

## ğŸš€ Contexte
AprÃ¨s ma formation intensive en **Data Science et Data Engineering (Jedha Bootcamp)**, je me lance dans la recherche de mon premier poste en Data.  
PlutÃ´t que de simplement suivre mes candidatures dans un tableau, jâ€™ai choisi dâ€™en faire un **projet analytique** :  
ğŸ‘‰ traiter mes candidatures comme un dataset  
ğŸ‘‰ les enrichir avec un modÃ¨le de langage (LLM)  
ğŸ‘‰ en tirer des visualisations (radars, distributions, tendances).  

Lâ€™objectif :  
- Prendre du recul sur mon parcours de recherche,  
- Mettre en avant mes compÃ©tences,  
- Partager mes insights 

---

## ğŸ—‚ DonnÃ©es
- **Source principale** : export de mon suivi de candidatures (CSV Notion).  
- **Colonnes clÃ©s** :  
  - `Entreprise`  
  - `Poste`  
  - `CatÃ©gorie Poste (LLM)` (classification via regex + LLM)  
  - `Ã‰tat` (sans rÃ©ponse, entretien, refus, etc.)  
  - `CompÃ©tences (LLM)` (extraites depuis les offres via scraping + LLM).  

---

## âš™ï¸ Pipeline (Notebook)
1. **PrÃ©paration & nettoyage**  
   - Uniformisation du CSV (sÃ©parateur, encodage, suppression des caractÃ¨res spÃ©ciaux).  
   - Classification des postes (`Data Analyst`, `Data Scientist`, `Data Engineer`, `Consultant Data`, `Autres`).  

2. **Enrichissement via LLM**  
   - Extraction des compÃ©tences clÃ©s Ã  partir des descriptions dâ€™offres.  
   - Transformation en format binaire (`1` si prÃ©sent, `0` sinon).  

3. **Analyses & Visualisations**  
   - ğŸ“ˆ **Distribution temporelle** des candidatures  
   - ğŸ“Š **RÃ©partition des postes** par catÃ©gorie  
   - ğŸŸ¦ **RÃ©partition des Ã©tats** (rÃ©ponses, sans rÃ©ponses, etc.)  
   - ğŸ•¸ **Radar chart** :  
     - CompÃ©tences du marchÃ© vs. mon profil  
     - Par catÃ©gorie de poste (Data Analyst, Data Scientist, etc.)  

---

## ğŸ“Š RÃ©sultats clÃ©s
- Nombre de candidatures envoyÃ©es : **281**  
- CatÃ©gorie la plus visÃ©e : **Data Analyst**  
- Taux de rÃ©ponses reÃ§ues : **37%** (Ã  complÃ©ter)  
- Matching compÃ©tences : bonne couverture en **Python, SQL, Machine Learning** mais lacunes sur **Cloud & Big Data** (axe dâ€™amÃ©lioration).  

---

## ğŸ› ï¸ Stack technique
- **Python** : Pandas, Seaborn, Matplotlib  
- **LLM** : Mistral API via LangChain (classification & extraction)  
- **Visualisation** : Radar charts custom + exports images  
- **Outils alternatifs** : Tableau Public, Metabase  

---

## ğŸ”® AmÃ©liorations possibles
- Enrichir la base avec des infos issues de **scraping avancÃ©** (LinkedIn, Indeed, WTTJ).  
- Industrialiser le pipeline (ETL automatisÃ© avec Airflow).  
- DÃ©ployer un **dashboard dynamique** (Streamlit ou Metabase).  

---

## ğŸ™Œ Remerciements 
Un coup de pouce particulier Ã  **ChatGPT** pour mâ€™avoir aidÃ© Ã  structurer et corriger ces notebook !  
